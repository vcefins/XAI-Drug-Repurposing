{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e58faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import yaml\n",
    "\n",
    "from rdflib import Graph, Literal, RDF, URIRef\n",
    "from rdflib.namespace import Namespace\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90416473",
   "metadata": {},
   "source": [
    "### DRKG Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b05300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000001685D759940>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "  File \"c:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\threading.py\", line 1479, in enumerate\n",
      "    def enumerate():\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "drkg_file = 'data/drkg/drkg.tsv'\n",
    "drkg_df = pd.read_csv(drkg_file, sep=\"\\t\", header=None)     # header fix to original code\n",
    "drkg_triplets_list = drkg_df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65a170",
   "metadata": {},
   "source": [
    "### DrugMechDB Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cc1ab52",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m drugmech_path = \u001b[33m\"\u001b[39m\u001b[33mdata/drugmech/drugmechdb.yaml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(drugmech_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         dmdb_yaml = \u001b[43myaml\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfh\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\__init__.py:125\u001b[39m, in \u001b[36msafe_load\u001b[39m\u001b[34m(stream)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msafe_load\u001b[39m(stream):\n\u001b[32m    118\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[33;03m    Parse the first YAML document in a stream\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[33;03m    and produce the corresponding Python object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m \u001b[33;03m    to be safe for untrusted input.\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSafeLoader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\__init__.py:81\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(stream, Loader)\u001b[39m\n\u001b[32m     79\u001b[39m loader = Loader(stream)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_single_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     83\u001b[39m     loader.dispose()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\constructor.py:49\u001b[39m, in \u001b[36mBaseConstructor.get_single_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_single_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Ensure that the stream contains a single document and construct it.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     51\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.construct_document(node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:36\u001b[39m, in \u001b[36mComposer.get_single_node\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     34\u001b[39m document = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(StreamEndEvent):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     document = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Ensure that the stream contains no more documents.\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(StreamEndEvent):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:55\u001b[39m, in \u001b[36mComposer.compose_document\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mself\u001b[39m.get_event()\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Compose the root node.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Drop the DOCUMENT-END event.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mself\u001b[39m.get_event()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:82\u001b[39m, in \u001b[36mComposer.compose_node\u001b[39m\u001b[34m(self, parent, index)\u001b[39m\n\u001b[32m     80\u001b[39m     node = \u001b[38;5;28mself\u001b[39m.compose_scalar_node(anchor)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(SequenceStartEvent):\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_sequence_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(MappingStartEvent):\n\u001b[32m     84\u001b[39m     node = \u001b[38;5;28mself\u001b[39m.compose_mapping_node(anchor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:111\u001b[39m, in \u001b[36mComposer.compose_sequence_node\u001b[39m\u001b[34m(self, anchor)\u001b[39m\n\u001b[32m    109\u001b[39m index = \u001b[32m0\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(SequenceEndEvent):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     node.value.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    112\u001b[39m     index += \u001b[32m1\u001b[39m\n\u001b[32m    113\u001b[39m end_event = \u001b[38;5;28mself\u001b[39m.get_event()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:84\u001b[39m, in \u001b[36mComposer.compose_node\u001b[39m\u001b[34m(self, parent, index)\u001b[39m\n\u001b[32m     82\u001b[39m     node = \u001b[38;5;28mself\u001b[39m.compose_sequence_node(anchor)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(MappingStartEvent):\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.ascend_resolver()\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:133\u001b[39m, in \u001b[36mComposer.compose_mapping_node\u001b[39m\u001b[34m(self, anchor)\u001b[39m\n\u001b[32m    129\u001b[39m item_key = \u001b[38;5;28mself\u001b[39m.compose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m item_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[32m    135\u001b[39m node.value.append((item_key, item_value))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:82\u001b[39m, in \u001b[36mComposer.compose_node\u001b[39m\u001b[34m(self, parent, index)\u001b[39m\n\u001b[32m     80\u001b[39m     node = \u001b[38;5;28mself\u001b[39m.compose_scalar_node(anchor)\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(SequenceStartEvent):\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_sequence_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(MappingStartEvent):\n\u001b[32m     84\u001b[39m     node = \u001b[38;5;28mself\u001b[39m.compose_mapping_node(anchor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:111\u001b[39m, in \u001b[36mComposer.compose_sequence_node\u001b[39m\u001b[34m(self, anchor)\u001b[39m\n\u001b[32m    109\u001b[39m index = \u001b[32m0\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(SequenceEndEvent):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     node.value.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    112\u001b[39m     index += \u001b[32m1\u001b[39m\n\u001b[32m    113\u001b[39m end_event = \u001b[38;5;28mself\u001b[39m.get_event()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:84\u001b[39m, in \u001b[36mComposer.compose_node\u001b[39m\u001b[34m(self, parent, index)\u001b[39m\n\u001b[32m     82\u001b[39m     node = \u001b[38;5;28mself\u001b[39m.compose_sequence_node(anchor)\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_event(MappingStartEvent):\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     node = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_mapping_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m.ascend_resolver()\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m node\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:133\u001b[39m, in \u001b[36mComposer.compose_mapping_node\u001b[39m\u001b[34m(self, anchor)\u001b[39m\n\u001b[32m    129\u001b[39m item_key = \u001b[38;5;28mself\u001b[39m.compose_node(node, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m#if item_key in node.value:\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m#    raise ComposerError(\"while composing a mapping\", start_event.start_mark,\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m#            \"found duplicate key\", key_event.start_mark)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m item_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompose_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[38;5;66;03m#node.value[item_key] = item_value\u001b[39;00m\n\u001b[32m    135\u001b[39m node.value.append((item_key, item_value))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\composer.py:64\u001b[39m, in \u001b[36mComposer.compose_node\u001b[39m\u001b[34m(self, parent, index)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompose_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, parent, index):\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAliasEvent\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     65\u001b[39m         event = \u001b[38;5;28mself\u001b[39m.get_event()\n\u001b[32m     66\u001b[39m         anchor = event.anchor\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\parser.py:98\u001b[39m, in \u001b[36mParser.check_event\u001b[39m\u001b[34m(self, *choices)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m         \u001b[38;5;28mself\u001b[39m.current_event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_event \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\parser.py:449\u001b[39m, in \u001b[36mParser.parse_block_mapping_value\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_token(ValueToken):\n\u001b[32m    448\u001b[39m     token = \u001b[38;5;28mself\u001b[39m.get_token()\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKeyToken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mValueToken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBlockEndToken\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    450\u001b[39m         \u001b[38;5;28mself\u001b[39m.states.append(\u001b[38;5;28mself\u001b[39m.parse_block_mapping_key)\n\u001b[32m    451\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parse_block_node_or_indentless_sequence()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\scanner.py:116\u001b[39m, in \u001b[36mScanner.check_token\u001b[39m\u001b[34m(self, *choices)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_token\u001b[39m(\u001b[38;5;28mself\u001b[39m, *choices):\n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# Check if the next token is one of the given types.\u001b[39;00m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.need_more_tokens():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfetch_more_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tokens:\n\u001b[32m    118\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m choices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\scanner.py:255\u001b[39m, in \u001b[36mScanner.fetch_more_tokens\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# It must be a plain scalar then.\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_plain():\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfetch_plain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# No? It's an error. Let's produce a nice error message.\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ScannerError(\u001b[33m\"\u001b[39m\u001b[33mwhile scanning for the next token\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    259\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfound character \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m that cannot start any token\u001b[39m\u001b[33m\"\u001b[39m % ch,\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m.get_mark())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\scanner.py:679\u001b[39m, in \u001b[36mScanner.fetch_plain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    676\u001b[39m \u001b[38;5;28mself\u001b[39m.allow_simple_key = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    678\u001b[39m \u001b[38;5;66;03m# Scan and add SCALAR. May change `allow_simple_key`.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m679\u001b[39m \u001b[38;5;28mself\u001b[39m.tokens.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_plain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\scanner.py:1303\u001b[39m, in \u001b[36mScanner.scan_plain\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1301\u001b[39m chunks.extend(spaces)\n\u001b[32m   1302\u001b[39m chunks.append(\u001b[38;5;28mself\u001b[39m.prefix(length))\n\u001b[32m-> \u001b[39m\u001b[32m1303\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1304\u001b[39m end_mark = \u001b[38;5;28mself\u001b[39m.get_mark()\n\u001b[32m   1305\u001b[39m spaces = \u001b[38;5;28mself\u001b[39m.scan_plain_spaces(indent, start_mark)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cefin\\anaconda3\\envs\\analysis-env\\Lib\\site-packages\\yaml\\reader.py:102\u001b[39m, in \u001b[36mReader.forward\u001b[39m\u001b[34m(self, length)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pointer+length+\u001b[32m1\u001b[39m >= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.buffer):\n\u001b[32m    101\u001b[39m     \u001b[38;5;28mself\u001b[39m.update(length+\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m length:\n\u001b[32m    103\u001b[39m     ch = \u001b[38;5;28mself\u001b[39m.buffer[\u001b[38;5;28mself\u001b[39m.pointer]\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m.pointer += \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "drugmech_path = \"data/drugmech/drugmechdb.yaml\"\n",
    "\n",
    "with open(drugmech_path, 'r') as fh:\n",
    "        dmdb_yaml = yaml.safe_load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d2fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dmdb_data_tools_analysis import *\n",
    "\n",
    "# all_metapath_nodes = get_metapath_node(dmdb_yaml)\n",
    "# all_metapath_edges = get_metapath_edges(dmdb_yaml)\n",
    "# basic_stats = defaultdict(list)\n",
    "\n",
    "# all_metaedges = []\n",
    "# all_parings = []\n",
    "# all_targets = []\n",
    "# unique_metaedges = []\n",
    "# first_edge_type = []\n",
    "# all_nodes = []\n",
    "\n",
    "# id_to_name = {}\n",
    "# id_to_label = {}\n",
    "\n",
    "# for i, p in enumerate(dmdb_yaml):\n",
    "#     _id = (p[\"graph\"][\"_id\"])\n",
    "#     drug_id, dis_id = path_to_tup(p)\n",
    "#     paths = get_all_paths(p)\n",
    "#     G = path_to_G(p)\n",
    "    \n",
    "#     G = add_metaedges(G)\n",
    "#     G = add_meanode_pairs(G)\n",
    "    \n",
    "#     basic_stats['idx'].append(i) #index\n",
    "#     basic_stats['id'].append(p['graph']['_id']) #DrugMechDB id\n",
    "#     basic_stats['drug'].append(drug_id) #Drug id\n",
    "#     basic_stats['disease'].append(dis_id)#Disease id\n",
    "#     basic_stats['nodes'].append((G.nodes)) #nodes in metapath\n",
    "#     basic_stats['n_nodes'].append(len(G.nodes)) # number of nodes in metapath\n",
    "#     basic_stats['n_edges'].append(len(G.edges)) #number of edges in metapath\n",
    "#     basic_stats['n_paths'].append(len(all_metapath_nodes[_id])) #number of paths\n",
    "#     basic_stats['metapath'].append(all_metapath_nodes[_id])\n",
    "#     basic_stats['metapath_with_edges'].append(all_metapath_edges[_id])\n",
    "\n",
    "    \n",
    "#     this_metaedges = [G.edges[e]['metaedge'] for e in G.edges]\n",
    "    \n",
    "#     all_metaedges += this_metaedges\n",
    "#     unique_metaedges += list(set(this_metaedges))\n",
    "    \n",
    "#     all_parings += [G.edges[e]['mn_pair'] for e in G.edges]\n",
    "#     all_targets += get_targets(G)\n",
    "#     first_edge_type += get_target_metaedges(G)\n",
    "#     all_nodes += list(G.nodes)\n",
    "    \n",
    "#     id_to_label = {**id_to_label, **get_id_to_type(G)}\n",
    "#     id_to_name = {**id_to_name, **get_id_to_name(G)}\n",
    "    \n",
    "# dmdb_df = pd.DataFrame(basic_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4cf738",
   "metadata": {},
   "source": [
    "<!-- ### DruugMechDB Import -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3635609f",
   "metadata": {},
   "source": [
    "## Entity Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e3e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_entry(entity,ent_type,dic, total_count):\n",
    "    if ent_type not in dic:\n",
    "        dic[ent_type]={}\n",
    "    ent_n_id=len(dic[ent_type])\n",
    "    if entity not in dic[ent_type]:\n",
    "        dic[ent_type][entity]=ent_n_id + total_count\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drkg_entity_dictionary={}\n",
    "total_count = 0\n",
    "\n",
    "for triple in drkg_triplets_list:\n",
    "    head,pred,tail = triple\n",
    "\n",
    "    head_type, head = head.split('::')\n",
    "    tail_type, tail = tail.split('::')\n",
    "    insert_entry(head,head_type,drkg_entity_dictionary,total_count)\n",
    "    total_count+=1\n",
    "    insert_entry(tail,tail_type,drkg_entity_dictionary,total_count)\n",
    "    total_count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dd0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "# Uses MESH and disregards DB for 'Drug' type\n",
    "dmdb_entity_dictionary = {}\n",
    "total_count = 0\n",
    "\n",
    "# DEBUG\n",
    "counter = 0\n",
    "debug_set = set()\n",
    "\n",
    "for entry in dmdb_yaml:\n",
    "    dbg_flag = 0\n",
    "    drug_db_id = entry['graph']['drugbank']\n",
    "    drug_mesh_id = entry['graph']['drug_mesh']       ## Can't trust the database, checking entity class\n",
    "\n",
    "    for node in entry['nodes']:\n",
    "        ent_id = node['id']\n",
    "        ent_type = node['label']\n",
    "        insert_entry(ent_id,ent_type,dmdb_entity_dictionary,total_count)\n",
    "        total_count+=1\n",
    "\n",
    "        if drug_mesh_id is not None and ent_id == drug_mesh_id:      # Extra (duplicate) log with drugbank id (only if drugmesh is not null)\n",
    "            insert_entry(drug_db_id,ent_type,dmdb_entity_dictionary,total_count)\n",
    "            total_count+=1\n",
    "            dbg_flag = 1\n",
    "\n",
    "        if drug_mesh_id is None:    ## for DEBUG - if null, DB id is used as default\n",
    "            dbg_flag = 1\n",
    "\n",
    "    if dbg_flag == 0:   ## for DEBUG\n",
    "        #print(drug_db_id)\n",
    "        debug_set.add(drug_db_id)\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "print(len(debug_set))   # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed91d758",
   "metadata": {},
   "source": [
    "### Inverse Dicts for Entity Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33174cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmdb_inv_ent_dict = {v: k for k, v in dmdb_entity_dictionary.items()}\n",
    "dmdb_inverse_ent_dict = {}\n",
    "for subdict in dmdb_entity_dictionary.values():\n",
    "    for k, v in subdict.items():\n",
    "        dmdb_inverse_ent_dict[v]=k\n",
    "\n",
    "\n",
    "#drkg_inv_ent_dict = {v: k for k, v in drkg_entity_dictionary.items()}\n",
    "drkg_inverse_ent_dict = {}\n",
    "for subdict in drkg_entity_dictionary.values():\n",
    "    for k, v in subdict.items():\n",
    "        drkg_inverse_ent_dict[v]=k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdec8b",
   "metadata": {},
   "source": [
    "## Discovering format-defying exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd7c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: How to handle exceptions\n",
    "\n",
    "def print_all_type(list,feat):\n",
    "    for l in list['nodes']:\n",
    "        print(l[feat])\n",
    "\n",
    "for entry in dmdb_yaml:\n",
    "    if entry['nodes'][0]['label'] == 'Drug' and entry['nodes'][-1]['label'] == 'Disease':\n",
    "        for idx, node in enumerate(entry['nodes']):\n",
    "            if idx == 0 or idx == (len(entry['nodes'])-1): continue\n",
    "            elif node['label'] == 'Drug' or node['label'] == 'Disease':\n",
    "                print_all_type(entry,'label')\n",
    "                print()\n",
    "    else:\n",
    "        print(\"\\t\", entry['nodes'][0]['label'], entry['nodes'][-1]['label'])\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e782de0",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12ae76",
   "metadata": {},
   "source": [
    "        drug: Ammonium lactate\n",
    "        drug_mesh: MESH:null\n",
    "\n",
    "DrugMechDB contains both  MESH:null and null for drug_mesh, and only one null for drugbank section.\n",
    "\n",
    "        drug: tazanolast\n",
    "        drug_mesh: MESH:C106301\n",
    "        drugbank: null\n",
    "\n",
    "And only two instances of double entries in drug_mesh:\n",
    "\n",
    "        drug: acrisorcin\n",
    "        drug_mesh: MESH:D000585, MESH:D006604\n",
    "        drugbank: DB:DB11254\n",
    "\n",
    "        drug: carfilzomib\n",
    "        drug_mesh: MESH:C524865, MESH:C519125\n",
    "        drugbank: DB:DB08889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8717f5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3135\n",
      "24313\n",
      "\n",
      "764\n",
      "5103\n"
     ]
    }
   ],
   "source": [
    "print(len(dmdb_entity_dictionary['Drug']))\n",
    "print(len(drkg_entity_dictionary['Compound']))\n",
    "print()\n",
    "print(len(dmdb_entity_dictionary['Disease']))\n",
    "print(len(drkg_entity_dictionary['Disease']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3985a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESH:D000068877\n",
      "DB02573\n",
      "\n",
      "MESH:D015464\n",
      "SARS-CoV2 E\n"
     ]
    }
   ],
   "source": [
    "def print_sample(dic, key):\n",
    "    for k,v in dic[key].items():\n",
    "        print(k)\n",
    "        break\n",
    "\n",
    "print_sample(dmdb_entity_dictionary, 'Drug')\n",
    "print_sample(drkg_entity_dictionary, 'Compound')\n",
    "print()\n",
    "print_sample(dmdb_entity_dictionary, 'Disease')\n",
    "print_sample(drkg_entity_dictionary, 'Disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce085d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4845"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 DrugBank ID is null\n",
    "\n",
    "cnt = 0\n",
    "for entry in dmdb_yaml:\n",
    "    elem = entry['graph']['drugbank']\n",
    "    if elem is None: \n",
    "        print(\"null\")\n",
    "        continue\n",
    "    if \"DB\" in elem:\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00da53ce",
   "metadata": {},
   "source": [
    "In DRKG;\n",
    "\n",
    "Compound::DB00898\n",
    "Compound::MESH:C106876      Disease::MESH:C537014\n",
    "Compound::MESH:D000588      Disease::MESH:D013274\n",
    "\n",
    "Compound::MESH:C554292|MESH:D013755\n",
    "\n",
    "\n",
    "In DMDB;\n",
    "\n",
    "drugbank: DB:DB09310\n",
    "drug_mesh: MESH:D000068877  disease_mesh: MESH:C567691\n",
    "\n",
    "drug_mesh: MESH:C524865, MESH:C519125"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a1db7",
   "metadata": {},
   "source": [
    "# Drugs, Diseases, & Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39af40d",
   "metadata": {},
   "source": [
    "## Drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157690ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_entry_eid(entity,ent_type,eid,dic):\n",
    "    if ent_type not in dic:\n",
    "        dic[ent_type]={}\n",
    "    ent_n_id=eid\n",
    "    if entity not in dic[ent_type]:\n",
    "        dic[ent_type][entity]=ent_n_id\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f01b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dmdb_entity_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m dmdb_drug_dict = {}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m drug, eid \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdmdb_entity_dictionary\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mDrug\u001b[39m\u001b[33m'\u001b[39m].items():\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m drug != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      5\u001b[39m         identifier, idx = drug.split(\u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'dmdb_entity_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "dmdb_drug_dict = {}\n",
    "\n",
    "for drug, eid in dmdb_entity_dictionary['Drug'].items():\n",
    "    if drug != None:\n",
    "        identifier, idx = drug.split(\":\")\n",
    "    insert_entry_eid(idx, identifier, eid, dmdb_drug_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da35eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmdb_entity_dictionary['Drug'][None]    # TODO: Not okay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47cb48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1556 MESH\n",
      "1577 DB\n",
      "1 CHEBI\n"
     ]
    }
   ],
   "source": [
    "for k,v in dmdb_drug_dict.items():\n",
    "    print(len(v),k)#,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c02b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "drkg_drug_dict = {}\n",
    "\n",
    "for drug,eid in drkg_entity_dictionary['Compound'].items():\n",
    "    if len(drug.split(\":\")) == 1:    # DB and CHEMBL\n",
    "        if 'DB' in drug:\n",
    "            insert_entry_eid(drug, 'DB', eid, drkg_drug_dict)\n",
    "        elif 'CHEMBL' in drug: \n",
    "            insert_entry_eid(drug, 'CHEMBL', eid, drkg_drug_dict)\n",
    "        else:\n",
    "            print(\"DEBUG Outlier with no split:\", drug)  \n",
    "    else:\n",
    "        if \"|\" in drug:       # Exceptions  --  MESH:C002480|MESH:, MESH:C011440|MESH:C046229,...\n",
    "            continue\n",
    "            # TODO: figure how to handle them appropriately\n",
    "        else:\n",
    "            identifier, idx = drug.split(\":\")\n",
    "            insert_entry_eid(idx, identifier, eid, drkg_drug_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432a5fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drkg_drug_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdrkg_drug_dict\u001b[49m.items():\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(v),k)\u001b[38;5;66;03m#,v)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'drkg_drug_dict' is not defined"
     ]
    }
   ],
   "source": [
    "for k,v in drkg_drug_dict.items():\n",
    "    print(len(v),k)#,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ffc83a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MESH'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m common_drug_dict = defaultdict(\u001b[38;5;28mtuple\u001b[39m)\n\u001b[32m      4\u001b[39m counter = [\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mesh_drug,dmdb_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdmdb_drug_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mMESH\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.items():\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mesh_drug \u001b[38;5;129;01min\u001b[39;00m drkg_drug_dict[\u001b[33m'\u001b[39m\u001b[33mMESH\u001b[39m\u001b[33m'\u001b[39m].keys():\n\u001b[32m      7\u001b[39m         \u001b[38;5;66;03m# common_drug_set.add('MESH:'+ mesh_dis)       # Re-adding identifier 'MESH:'\u001b[39;00m\n\u001b[32m      8\u001b[39m         common_drug_dict[\u001b[33m'\u001b[39m\u001b[33mMESH:\u001b[39m\u001b[33m'\u001b[39m+ mesh_drug] = (dmdb_id,drkg_drug_dict[\u001b[33m'\u001b[39m\u001b[33mMESH\u001b[39m\u001b[33m'\u001b[39m][mesh_drug])\n",
      "\u001b[31mKeyError\u001b[39m: 'MESH'"
     ]
    }
   ],
   "source": [
    "# common_drug_set = set()\n",
    "common_drug_dict = defaultdict(tuple)\n",
    "\n",
    "counter = [0,0,0]\n",
    "for mesh_drug,dmdb_id in dmdb_drug_dict['MESH'].items():\n",
    "    if mesh_drug in drkg_drug_dict['MESH'].keys():\n",
    "        # common_drug_set.add('MESH:'+ mesh_dis)       # Re-adding identifier 'MESH:'\n",
    "        common_drug_dict['MESH:'+ mesh_drug] = (dmdb_id,drkg_drug_dict['MESH'][mesh_drug])\n",
    "        counter[0]+=1\n",
    "for db_drug,dmdb_id in dmdb_drug_dict['DB'].items():\n",
    "    if db_drug in drkg_drug_dict['DB'].keys():\n",
    "        # common_drug_set.add('DB:'+ mesh_dis)       # Re-adding identifier 'DB:'\n",
    "        common_drug_dict['DB:'+ db_drug] = (dmdb_id,drkg_drug_dict['DB'][db_drug])\n",
    "        counter[1]+=1\n",
    "for chebi_drug,dmdb_id in dmdb_drug_dict['CHEBI'].items():\n",
    "    if chebi_drug in drkg_drug_dict['CHEBI'].keys():\n",
    "        # common_drug_set.add('CHEBI:'+ mesh_dis)       # Re-adding identifier 'CHEBI:'\n",
    "        common_drug_dict['CHEBI:'+ chebi_drug] = (dmdb_id,drkg_drug_dict['CHEBI'][chebi_drug])\n",
    "        counter[2]+=1\n",
    "\n",
    "print(\"Number of common drugs [MESH/DB/CHEBI]:\", len(common_drug_dict), counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d53a0",
   "metadata": {},
   "source": [
    "## Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6405e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmdb_disease_dict = {}\n",
    "\n",
    "for disease, eid in dmdb_entity_dictionary['Disease'].items():\n",
    "    identifier, idx = disease.split(\":\")\n",
    "    insert_entry_eid(idx, identifier, eid, dmdb_disease_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f6b26932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758 MESH\n",
      "5 DB\n",
      "1 HP\n"
     ]
    }
   ],
   "source": [
    "for k,v in dmdb_disease_dict.items():\n",
    "    print(len(v),k)#,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "328ae728",
   "metadata": {},
   "outputs": [],
   "source": [
    "drkg_disease_dict = {}\n",
    "\n",
    "for disease, eid in drkg_entity_dictionary['Disease'].items():\n",
    "    if len(disease.split(\":\")) != 2:\n",
    "        insert_entry_eid(disease, 'other', eid, drkg_disease_dict)\n",
    "    else:\n",
    "        identifier, idx = disease.split(\":\")\n",
    "        insert_entry_eid(idx, identifier, eid, drkg_disease_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3a83fae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 other\n",
      "4871 MESH\n",
      "78 OMIM\n",
      "127 DOID\n"
     ]
    }
   ],
   "source": [
    "for k,v in drkg_disease_dict.items():\n",
    "    print(len(v),k)#,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "842b5a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common MESH diseases: 714\n"
     ]
    }
   ],
   "source": [
    "# MESH\n",
    "# common_disease_set = set()\n",
    "common_disease_dict = defaultdict(tuple)\n",
    "\n",
    "for mesh_dis,dmdb_id in dmdb_disease_dict['MESH'].items():\n",
    "    if mesh_dis in drkg_disease_dict['MESH'].keys():\n",
    "        # common_disease_set.add('MESH:'+ mesh_dis)       # Re-adding identifier 'MESH:'\n",
    "        common_disease_dict['MESH:'+ mesh_dis] = (dmdb_id,drkg_disease_dict['MESH'][mesh_dis])\n",
    "\n",
    "print(\"Number of common MESH diseases:\", len(common_disease_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2fbbe",
   "metadata": {},
   "source": [
    "# Common Pairs\n",
    "\n",
    "TODO : Include entity dictionary IDs for keeping track, use it in paths too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d236f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entry in dmdb_yaml:\n",
    "#     dis_mesh = entry['graph']['disease_mesh']\n",
    "#     if len(dis_mesh.split(':')) != 2:\n",
    "#         print(dis_mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if both drug and disease elements exist in common entities\n",
    "# TODO: How is it possible that there are duplicates? (184 duplicates)\n",
    "\n",
    "# count = [0,0,0]\n",
    "# common_pairs = set()\n",
    "\n",
    "# for entry in dmdb_yaml:\n",
    "#     graph_dict = entry['graph']\n",
    "#     count[2] += 1\n",
    "#     db_id = graph_dict['drugbank']\n",
    "#     mesh_id = graph_dict['drug_mesh']\n",
    "#     dis_id = graph_dict['disease_mesh']\n",
    "\n",
    "#     if db_id in common_drug_dict and db_id != None:\n",
    "#         if dis_id in common_disease_dict:\n",
    "#             if (db_id, dis_id) in common_pairs:\n",
    "#                 print(\"Duplicate\", (db_id, dis_id))\n",
    "#             common_pairs.add((db_id, dis_id))\n",
    "#             count[0] += 1\n",
    "#         else: count[1] += 1\n",
    "#     elif mesh_id in common_drug_dict and mesh_id != None and mesh_id != 'MESH:null':\n",
    "#         if dis_id in common_disease_dict:\n",
    "#             if (mesh_id, dis_id) in common_pairs:\n",
    "#                 print(\"Duplicate\", (mesh_id, dis_id))\n",
    "#             common_pairs.add((mesh_id, dis_id))\n",
    "#             count[0] += 1\n",
    "#         else: count[1] += 1\n",
    "#     else:\n",
    "#         count[1] += 1\n",
    "\n",
    "\n",
    "# print(\"Number of common drug-disease pairs:\", len(common_pairs))\n",
    "# print(\"[DB, MESH, Total]\", count)\n",
    "\n",
    "# Number of common drug-disease pairs: 4484\n",
    "# [DB, MESH, Total] [4668, 178, 4846]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b094e0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common drug-disease pairs: 4484 / 4846\n"
     ]
    }
   ],
   "source": [
    "common_pairs_dict = defaultdict()\n",
    "\n",
    "for entry in dmdb_yaml:\n",
    "    graph_dict = entry['graph']\n",
    "    db_id = graph_dict['drugbank']\n",
    "    mesh_id = graph_dict['drug_mesh']\n",
    "    dis_id = graph_dict['disease_mesh']\n",
    "\n",
    "    if db_id in common_drug_dict and db_id != None:     # Drugbank ID\n",
    "        if dis_id in common_disease_dict:\n",
    "            common_pairs_dict[(db_id,dis_id)] = 'DB' # = ((dmdb_drug_dict['DB'][db_id],drkg_drug_dict['DB'][db_id]),(dmdb_disease_dict['MESH'][dis_id],drkg_disease_dict['MESH'][dis_id]))\n",
    "    elif mesh_id in common_drug_dict and mesh_id != None and mesh_id != 'MESH:null':    # Drug Mesh ID  - no duplicates (Drugbank ID has priority)\n",
    "        if dis_id in common_disease_dict:\n",
    "            common_pairs_dict[(mesh_id,dis_id)] = 'MESH'\n",
    "\n",
    "print(\"Number of common drug-disease pairs:\", len(common_pairs_dict),'/',len(dmdb_yaml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "657bc89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DRUG) DMDB Entity index, DRKG Entity index: 2 169474\n",
      "(DISEASE) DMDB Entity index, DRKG Entity index: 3 3039657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing reverse pair search\n",
    "for common_pair in common_pairs_dict.keys():\n",
    "    common_drug, common_disease = common_pair\n",
    "    d_type, drug = common_drug.split(':')\n",
    "    dis_type, disease = common_disease.split(':')\n",
    "    print(\"(DRUG) DMDB Entity index, DRKG Entity index:\", dmdb_drug_dict[d_type][drug], drkg_drug_dict[d_type][drug])\n",
    "    print(\"(DISEASE) DMDB Entity index, DRKG Entity index:\", dmdb_disease_dict[dis_type][disease], drkg_disease_dict[dis_type][disease])\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a79ac3",
   "metadata": {},
   "source": [
    "# Pathing strategy for DrugMechDB\n",
    "\n",
    "Determine the data structure formatting to store the subgraph structure. Use integer IDs in entity dictionaries and focus on connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f238eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f56b9d5c",
   "metadata": {},
   "source": [
    "# GNN Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0c5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import trained GNNs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c166bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format inputs appropriately (care splitting training/eval/test datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c31ead",
   "metadata": {},
   "source": [
    "## Saliency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a409c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mask nodes from SM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7aad2",
   "metadata": {},
   "source": [
    "## Subgraph Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff73368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare prediction paths of Saliency Maps and ground-truth DrugMechDB subgraph samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
